{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 패키지 설치\n",
        "!pip install konlpy\n",
        "!pip install wordcloud\n",
        "!pip install pandas matplotlib"
      ],
      "metadata": {
        "id": "lJJDLLuG4Q52",
        "collapsed": true
      },
      "id": "lJJDLLuG4Q52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 데이터 전처리**\n",
        "* 추출한 텍스트 데이터를 바탕으로 전처리 하는 코드\n",
        "* 전체 학생 데이터에서 학과, 전형, 창체기록을 추출하여 하나의 텍스트 파일을 생성함\n",
        "* 생성한 텍스트 파일에서 키워드를 추출하여 csv 파일로 저장함"
      ],
      "metadata": {
        "id": "8TxVQQAOixw6"
      },
      "id": "8TxVQQAOixw6"
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 폰트 설치 및 확인\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq fonts-nanum\n",
        "!fc-list :lang=ko"
      ],
      "metadata": {
        "id": "SOaYx_Ek5sVD",
        "collapsed": true
      },
      "id": "SOaYx_Ek5sVD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/생기부_원본_수정_txt.zip\"\n",
        "extract_path = \"/content/records\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "os.listdir(extract_path)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EwWrNQGwaPLq"
      },
      "id": "EwWrNQGwaPLq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "for file in os.listdir(\"/content/records\"):\n",
        "    if file.endswith(\".txt\"):\n",
        "        with open(f\"/content/records/{file}\", \"r\", encoding=\"utf-8\") as f:\n",
        "            texts.append(f.read())\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vinlUx3nadUO"
      },
      "id": "vinlUx3nadUO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. 창체기록 추출\n",
        "\n"
      ],
      "metadata": {
        "id": "SLZ5BhVopb6O"
      },
      "id": "SLZ5BhVopb6O"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "# Colab 세션의 기본 경로(/content)에 직접 데이터 파일들을 업로드함\n",
        "TARGET_DIR = \"/content/records\"\n",
        "\n",
        "# 결과를 저장할 파일 이름\n",
        "OUTPUT_FILENAME = 'data.txt'\n",
        "\n",
        "# 전체 학생 파일에서 정보를 추출하여 하나의 파일로 합치는 함수\n",
        "def extract_info_and_combine(target_dir, output_filename):\n",
        "\n",
        "    # 파일이 저장될 최종 경로 설정\n",
        "    output_path = \"/content/data.txt\"\n",
        "\n",
        "    # 불필요한 텍스트 제거\n",
        "    unwanted_patterns = re.compile(\n",
        "        r\"정부24|학년|학\\s*년|영역|---|Page|\\* 본 증명서는 열람용이며, 법적 효력이 없습니다:|일자|창 의 적 체 험 활 동|특기사항|특기 사항\",\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "    processed_count = 0\n",
        "\n",
        "    # 디렉토리에서 파일 목록 가져오기\n",
        "    try:\n",
        "      files_to_process = [f for f in os.listdir(target_dir)\n",
        "                    if f.endswith('.txt') and f != output_filename]\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\n⚠️ 오류: 대상 디렉토리 '{target_dir}'를 찾을 수 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # 결과를 저장할 파일 열기\n",
        "    try:\n",
        "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
        "\n",
        "            for filename in files_to_process:\n",
        "\n",
        "                # 파일명에서 학과, 전형 추출\n",
        "                try:\n",
        "                    base_name = filename[:-4]\n",
        "                    parts = base_name.split('_')\n",
        "\n",
        "                    if len(parts) >= 5:\n",
        "                        학과 = parts[2]\n",
        "                        전형 = parts[4]\n",
        "                    else:\n",
        "                        print(f\"⚠️ 파일명 규칙 불일치 (건너뜀): {filename}\")\n",
        "                        continue\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ 파일명 분석 오류 발생 (건너뜀): ({filename}): {e}\")\n",
        "                    continue\n",
        "\n",
        "                # 학과 이름 통일\n",
        "                original_학과 = 학과\n",
        "\n",
        "                if 학과 == \"컴퓨터과학전공\":\n",
        "                    학과 = \"컴퓨터과학과\"\n",
        "\n",
        "                # 자유전공은 계열을 명시하지 않은 학생들도 있어 하나로 통일함\n",
        "                elif 학과 in [\"자유전공(it계열)\", \"자유전공학부(인문사회계열)\", \"자율전공\"]:\n",
        "                    학과 = \"자유전공학부\"\n",
        "\n",
        "                # 3. 지능IoT융합은 지능IoT로 변경\n",
        "                elif 학과 in [\"지능IoT융합\", \"지능IOT\"]:\n",
        "                    학과 = \"지능IoT\"\n",
        "\n",
        "                # 파일 경로\n",
        "                file_path = os.path.join(target_dir, filename)\n",
        "\n",
        "                # 파일 내용 읽기\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding='utf-8') as infile:\n",
        "                        content = infile.read()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ 파일 읽기 오류 발생 (건너뜀): ({filename}): {e}\")\n",
        "                    continue\n",
        "\n",
        "                # 창체기록 추출\n",
        "                # 시작점: \"창의적 체험활동상황\", 끝점: \"봉 사 활 동 실 적\"\n",
        "                # 창체기록 추출 (PDF → txt 변환 특성 고려)\n",
        "                # '창의적 체험활동'이라는 말이 나오면 그 뒤를 전부 사용\n",
        "                match = re.search(r\"창의적\\s*체험활동[\\s\\S]*\", content)\n",
        "\n",
        "                if match:\n",
        "                    창체기록_raw = match.group(0)\n",
        "\n",
        "                    # 불필요한 텍스트 제거\n",
        "                    창체기록_clean = unwanted_patterns.sub('', 창체기록_raw)\n",
        "\n",
        "                    # 공백 정리\n",
        "                    창체기록 = re.sub(r'\\s{2,}', ' ', 창체기록_clean).strip()\n",
        "                else:\n",
        "                    print(f\"⚠️ 창체기록 미발견 (건너뜀): {filename}\")\n",
        "                    continue\n",
        "\n",
        "\n",
        "                # 결과 파일에 형식에 맞게 저장\n",
        "                outfile.write(f\"{학과}\\n\")\n",
        "                outfile.write(f\"{전형}\\n\")\n",
        "                outfile.write(f\"{창체기록}\\n\")\n",
        "                outfile.write(\"---\\n\")    # 각 학생 구분자\n",
        "\n",
        "                processed_count += 1    # 처리된 파일 개수 저장\n",
        "\n",
        "        print(f\"✅ 총 {processed_count}개 파일 처리 완료\")\n",
        "        print(f\"✅ {output_filename}파일 저장 완료\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n⚠️ 치명적인 오류 발생: {e}\")\n",
        "\n",
        "# 함수 실행\n",
        "extract_info_and_combine(TARGET_DIR, OUTPUT_FILENAME)"
      ],
      "metadata": {
        "id": "TRTsoew0-cem",
        "collapsed": true
      },
      "id": "TRTsoew0-cem",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. 학과, 전형 및 창체기록 키워드 추출"
      ],
      "metadata": {
        "id": "E-mTZuQbp5KP"
      },
      "id": "E-mTZuQbp5KP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c97d54-97da-46cc-82ad-e7afb8181fcc",
      "metadata": {
        "id": "49c97d54-97da-46cc-82ad-e7afb8181fcc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "# KoNLPy의 Okt 분석기\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "\n",
        "# 파일명 설정\n",
        "RAW_TEXT_FILE = 'data.txt'\n",
        "OUTPUT_CSV_FILE = 'keyword_processed_data.csv'\n",
        "\n",
        "# KoNLPy의 Okt 분석기 초기화(Okt는 명사를 추출함)\n",
        "okt = Okt()\n",
        "\n",
        "# KoNLPy의 Okt 분석기 초기화(Okt는 명사를 추출함)\n",
        "okt = Okt()\n",
        "\n",
        "# 분석에 불필요한 단어 정의(불용어)\n",
        "custom_stopwords = ['년', '월', '일', '등', '것', '수', '위해', '참여', '보고서', '학년', '시간', '과정', '통해', '함께', '또한', '진로', '자신', '대한', '대해',\n",
        "                    '활동', '관련', '관심', '분야', '계기', '생각', '학급', '학생', '직업', '방법', '활용', '이해', '교육', '가짐', '교내', '동안', '학교', '작성',\n",
        "                    '자살', '모습', '예방', '통일', '가지', '희망', '프로', '학기', '수업', '본인', '학과', '검사', '인식']\n",
        "\n",
        "\n",
        "# 데이터 추출 함수\n",
        "\n",
        "# 태그 제거 및 공백 정리\n",
        "def clean_line_tag(line):\n",
        "    cleaned_line = re.sub(r'\\\\', '', line)\n",
        "    return cleaned_line.strip()\n",
        "\n",
        "# 학과, 전형, 창체 기록 추출\n",
        "def extract_raw_data(file_path):\n",
        "    students_data = []\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            raw_text = f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ 오류: 파일을 찾을 수 없습니다: {file_path}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    blocks = raw_text.strip().split('---')\n",
        "\n",
        "    for i, block in enumerate(blocks):\n",
        "        block_text = block.strip()\n",
        "        if not block_text:\n",
        "            continue\n",
        "\n",
        "        lines = [line.strip() for line in block_text.split('\\n') if line.strip()]\n",
        "\n",
        "        if len(lines) < 3:\n",
        "            continue\n",
        "\n",
        "        original_creative_text = ' '.join(lines[2:])\n",
        "\n",
        "        record = {\n",
        "            '학과': clean_line_tag(lines[0]),\n",
        "            '전형': clean_line_tag(lines[1]),\n",
        "            '창체 기록_원본': original_creative_text.strip()\n",
        "        }\n",
        "        students_data.append(record)\n",
        "\n",
        "    return pd.DataFrame(students_data)\n",
        "\n",
        "\n",
        "# 최종 전처리 함수 (Okt 명사 추출 방식)\n",
        "def preprocess_text_okt_nouns(text, analyzer, custom_stopwords):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return ''\n",
        "\n",
        "    # 숫자, 특수문자 제거 (명사 추출 전 수행)\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'[0-9]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Okt 분석기로 명사만 추출 (서술어 자동 제거)\n",
        "    try:\n",
        "        tokens = analyzer.nouns(text)\n",
        "    except Exception as e:\n",
        "        # Okt 분석 중 오류 발생 시 건너뜀\n",
        "        print(f\"⚠️ Okt 분석 중 오류 발생 (건너뜀): {e}\")\n",
        "        return ''\n",
        "\n",
        "    # 필터링 (불용어 및 길이)\n",
        "    final_tokens = [\n",
        "        word for word in tokens\n",
        "        if word not in custom_stopwords and len(word) > 1\n",
        "    ]\n",
        "\n",
        "    return ', '.join(final_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. 데이터 로드 및 정리"
      ],
      "metadata": {
        "id": "haT9_VQnqIem"
      },
      "id": "haT9_VQnqIem"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/data.txt\n",
        "!sed -n '1,20p' /content/data.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ycq1kxs0p80J"
      },
      "id": "Ycq1kxs0p80J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcad9959-3ea6-480c-b657-edaf8a5b03af",
      "metadata": {
        "id": "fcad9959-3ea6-480c-b657-edaf8a5b03af",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data_df = extract_raw_data(RAW_TEXT_FILE)\n",
        "\n",
        "if data_df.empty:\n",
        "    raise Exception(\"⚠️ 데이터 로드 실패. 파일 경로 및 형식을 확인하세요.\")\n",
        "\n",
        "print(f\"✅ 총 {len(data_df)}명의 학생 데이터 로드 완료\")\n",
        "\n",
        "# 결측값 및 공백 값 정리\n",
        "data_df['창체 기록_원본'] = data_df['창체 기록_원본'].fillna('')\n",
        "data_df = data_df[data_df['창체 기록_원본'].str.strip().str.len() > 0].copy()\n",
        "\n",
        "print(f\"✅ 데이터 정리 완료. 최종 데이터 행 수: {len(data_df)}\")\n",
        "\n",
        "# 상위 5개 행 출력(확인용)\n",
        "print(data_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. 전처리 적용 및 명사 리스트 컬럼 생성"
      ],
      "metadata": {
        "id": "dvfpgd9jqOE-"
      },
      "id": "dvfpgd9jqOE-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd528a56-02de-4dd0-aeba-7ccf38cb8b39",
      "metadata": {
        "id": "dd528a56-02de-4dd0-aeba-7ccf38cb8b39",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Okt 분석기, 불용어 리스트 사용하여 전처리 적용\n",
        "data_df['명사 리스트'] = data_df['창체 기록_원본'].apply(\n",
        "    lambda x: preprocess_text_okt_nouns(x, okt, custom_stopwords))\n",
        "\n",
        "print(\"✅ 전처리 완료\")\n",
        "\n",
        "#상위 5개 행 출력(확인용)\n",
        "print(data_df[['학과', '전형', '명사 리스트']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. 최종 결과 CSV파일로 저장"
      ],
      "metadata": {
        "id": "_awtXrJxqlyi"
      },
      "id": "_awtXrJxqlyi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07899270-04a3-4aa1-8a5b-bb9aedb087fd",
      "metadata": {
        "id": "07899270-04a3-4aa1-8a5b-bb9aedb087fd",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data_df.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"\\n✅ '{OUTPUT_CSV_FILE}' 파일 저장 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. 키워드 빈도 분석 (wordcloud)**  \n",
        "* 전체 및 학과, 전형 별 워드 클라우드 생성  \n",
        "* 주요 키워드(상위 10개) 개수 출력\n",
        "* 학과별 워드 클라우드에서 컴퓨터과학과가 가장 먼저 출력되도록 함\n",
        "* 학과별, 전형별 워드 클라우드에서 캔버스가 2개씩 출력되며 각 캔버스 밑에 개수가 출력되도록 함\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9PgQHYKsmhpP"
      },
      "id": "9PgQHYKsmhpP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. 데이터 파일 로드"
      ],
      "metadata": {
        "id": "sk53HQdqzXIR"
      },
      "id": "sk53HQdqzXIR"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.font_manager as fm\n",
        "import pandas as pd\n",
        "\n",
        "# 폰트 지정\n",
        "FONT_PATH = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "\n",
        "# 저장된 파일 이름 확인\n",
        "INPUT_CSV_FILE = 'keyword_processed_data.csv'\n",
        "\n",
        "# 전처리 완료된 CSV 파일 로드\n",
        "analysis_df = pd.read_csv(INPUT_CSV_FILE, encoding='utf-8-sig')\n",
        "\n",
        "# 폰트 속성 객체 생성 (제목 깨짐 방지용)\n",
        "title_font_prop = fm.FontProperties(fname=FONT_PATH, size=18)"
      ],
      "metadata": {
        "id": "x71GNTrL7tfM"
      },
      "id": "x71GNTrL7tfM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. 키워드 개수 계산 및 출력 함수"
      ],
      "metadata": {
        "id": "8BKJIfzXzwXE"
      },
      "id": "8BKJIfzXzwXE"
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 10개 키워드 개수 계산 및 출력 함수\n",
        "from collections import Counter\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "def keyword_counts(group_name, text_data):\n",
        "    if not text_data.strip():\n",
        "        return {\n",
        "            'major': group_name,\n",
        "            'keywords': [\"키워드 데이터가 비어 있습니다.\"]\n",
        "        }\n",
        "\n",
        "    # 텍스트 데이터를 공백 기준으로 토큰화하고 빈도 계산\n",
        "    tokens = text_data.split(' ')\n",
        "    word_counts = Counter(tokens)\n",
        "\n",
        "    # 공백 토큰 제거\n",
        "    if '' in word_counts:\n",
        "        del word_counts['']\n",
        "\n",
        "    top_10 = word_counts.most_common(10)\n",
        "\n",
        "    # 학과명과 키워드 목록을 딕셔너리로 반환\n",
        "    return {\n",
        "        'major': group_name,\n",
        "        'keywords': [f\"{keyword}: {count}개\" for keyword, count in top_10]\n",
        "    }\n",
        "\n",
        "\n",
        "# 주요 키워드 목록 출력 위치 지정 함수\n",
        "def plot_keywords_on_axis(keywords_list, ax_text, font_prop, font_size=14):\n",
        "    header = \"[주요 키워드 개수]\"\n",
        "    text_content = header + \"\\n\" + \"\\n\".join(keywords_list)\n",
        "\n",
        "    # 텍스트 영역에 주요 키워드 개수 출력\n",
        "    ax_text.text(\n",
        "        0.0, 0.95,\n",
        "        text_content,\n",
        "        transform=ax_text.transAxes,\n",
        "        fontproperties=font_prop,\n",
        "        fontsize=font_size,\n",
        "        verticalalignment='top',\n",
        "        horizontalalignment='left',\n",
        "        color='black'\n",
        "    )\n",
        "    ax_text.axis('off') # 축 숨기기"
      ],
      "metadata": {
        "id": "aV2_8BjE9Uj8"
      },
      "id": "aV2_8BjE9Uj8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. 워드 클라우드 시각화\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IrIFtEB3zf5B"
      },
      "id": "IrIFtEB3zf5B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1. 전체 워드 클라우드"
      ],
      "metadata": {
        "id": "fba-HLff08Y0"
      },
      "id": "fba-HLff08Y0"
    },
    {
      "cell_type": "code",
      "source": [
        "# 워드 클라우드 시각화\n",
        "# 전체 워드 클라우드\n",
        "\n",
        "all_words = ' '.join(analysis_df['명사 리스트'].str.replace(',', ' ').dropna())\n",
        "\n",
        "wc = WordCloud(\n",
        "    font_path=FONT_PATH,\n",
        "    width=1000,\n",
        "    height=600,\n",
        "    background_color='white',\n",
        "    max_words=100,\n",
        "    prefer_horizontal=0.9\n",
        ")\n",
        "wordcloud = wc.generate(all_words)\n",
        "\n",
        "# 키워드 데이터 추출\n",
        "result = keyword_counts(\"전체 분석\", all_words)\n",
        "keywords_list = result['keywords']\n",
        "\n",
        "# 캔버스와 GridSpec 설정\n",
        "fig = plt.figure(figsize=(9, 8))\n",
        "gs_main = GridSpec(1, 1, figure=fig)\n",
        "\n",
        "# 중첩 GridSpec 생성(워드 클라우드와 텍스트가 겹치지 않도록 분리)\n",
        "gs_nested = gs_main[0].subgridspec(10, 1, hspace=0.1)\n",
        "\n",
        "ax_wc = fig.add_subplot(gs_nested[0:8, 0])  # 워드 클라우드 영역 (상단 80%)\n",
        "ax_text = fig.add_subplot(gs_nested[8:10, 0]) # 텍스트 영역 (하단 20%)\n",
        "\n",
        "# 워드 클라우드 시각화\n",
        "ax_wc.imshow(wordcloud, interpolation='bilinear')\n",
        "ax_wc.axis('off')\n",
        "ax_wc.set_title(\"전체 핵심 키워드 분석\", fontproperties=title_font_prop)\n",
        "\n",
        "# 키워드 개수 출력\n",
        "plot_keywords_on_axis(keywords_list, ax_text, title_font_prop, font_size=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I1yL_mvnARfS"
      },
      "id": "I1yL_mvnARfS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2. 학과별 워드 클라우드"
      ],
      "metadata": {
        "id": "qehGBRhs2zHp"
      },
      "id": "qehGBRhs2zHp"
    },
    {
      "cell_type": "code",
      "source": [
        "# 학과별 워드 클라우드\n",
        "grouped_data = analysis_df.groupby('학과')['명사 리스트'].apply(\n",
        "    lambda x: ' '.join(x.str.replace(',', ' ').dropna())\n",
        ")\n",
        "\n",
        "# 컴퓨터과학과가 가장 먼저 출력되도록 지정\n",
        "TARGET_MAJOR = '컴퓨터과학과'\n",
        "ordered_data = []\n",
        "\n",
        "# 컴퓨터과학과 데이터 추출 및 맨 앞에 추가\n",
        "if TARGET_MAJOR in grouped_data:\n",
        "    ordered_data.append((TARGET_MAJOR, grouped_data[TARGET_MAJOR]))\n",
        "\n",
        "    # 나머지 학과 데이터 추가\n",
        "    remaining_items = [(major, text)\n",
        "                       for major, text in grouped_data.items()\n",
        "                       if major != TARGET_MAJOR]\n",
        "    ordered_data.extend(remaining_items)\n",
        "else:\n",
        "    ordered_data = list(grouped_data.items())\n",
        "\n",
        "num_groups = len(ordered_data)\n",
        "MAX_COLS = 2 # 각 행에 캔버스 2개씩 출력\n",
        "\n",
        "# 그룹화된 데이터가 있을 경우 시각화 진행\n",
        "if num_groups > 0:\n",
        "    # 총 필요한 행 수 계산\n",
        "    nrows = math.ceil(num_groups / MAX_COLS)\n",
        "    fig = plt.figure(figsize=(6 * MAX_COLS, 8.5 * nrows))\n",
        "\n",
        "    # 메인 GridSpec 생성\n",
        "    gs_main = GridSpec(nrows, MAX_COLS, figure=fig)\n",
        "\n",
        "    # 워드 클라우드 생성\n",
        "    # ordered_data 순회 (정해진 순서대로 순회)\n",
        "    for i, (major, text) in enumerate(ordered_data):\n",
        "\n",
        "        # 현재 학과가 들어갈 위치 계산\n",
        "        row_idx = i // MAX_COLS\n",
        "        col_idx = i % MAX_COLS\n",
        "\n",
        "        # 해당 위치에 중첩 GridSpec 생성(워드클라우드와 텍스트가 겹치지 않도록 함)\n",
        "        gs_nested = gs_main[row_idx, col_idx].subgridspec(10, 1, hspace=0.1)\n",
        "\n",
        "        # 서브 영역 할당\n",
        "        ax_wc = fig.add_subplot(gs_nested[0:8, 0])  # 워드 클라우드 영역 (상단 80%)\n",
        "        ax_text = fig.add_subplot(gs_nested[8:10, 0]) # 키워드 텍스트 영역 (하단 20%)\n",
        "\n",
        "        # 워드 클라우드 및 데이터 처리\n",
        "        result = keyword_counts(major, text)\n",
        "        keywords_list = result['keywords']\n",
        "\n",
        "        wc_major = WordCloud(\n",
        "            font_path=FONT_PATH,\n",
        "            width=800,\n",
        "            height=800,\n",
        "            background_color='white',\n",
        "            max_words=50\n",
        "        )\n",
        "        wordcloud_major = wc_major.generate(text)\n",
        "\n",
        "        # 워드 클라우드 시각화\n",
        "        ax_wc.imshow(wordcloud_major, interpolation='bilinear')\n",
        "        ax_wc.axis('off')\n",
        "        ax_wc.set_title(f\"학과: {major}\", fontproperties=title_font_prop)\n",
        "\n",
        "        # 주요 키워드 개수 출력\n",
        "        plot_keywords_on_axis(keywords_list, ax_text, title_font_prop, font_size=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"\\n학과별 그룹화할 데이터가 충분하지 않습니다.\")"
      ],
      "metadata": {
        "id": "gW9qNiO59aft"
      },
      "id": "gW9qNiO59aft",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.3. 전형별 워드 클라우드"
      ],
      "metadata": {
        "id": "FKxyW_-n25XC"
      },
      "id": "FKxyW_-n25XC"
    },
    {
      "cell_type": "code",
      "source": [
        "# 전형별 워드 클라우드\n",
        "grouped_data2 = analysis_df.groupby('전형')['명사 리스트'].apply(\n",
        "    lambda x: ' '.join(x.str.replace(',', ' ').dropna())\n",
        ")\n",
        "num_groups = len(grouped_data2)\n",
        "MAX_COLS = 2 # 각 행에 캔버스 2개씩 출력\n",
        "\n",
        "if num_groups > 0:\n",
        "\n",
        "    # 총 필요한 행 수 계산\n",
        "    nrows = math.ceil(num_groups / MAX_COLS)\n",
        "    fig = plt.figure(figsize=(6 * MAX_COLS, 8.5 * nrows))\n",
        "\n",
        "    # 메인 GridSpec 생성\n",
        "    gs_main = GridSpec(nrows, MAX_COLS, figure=fig)\n",
        "\n",
        "    # 전형별 워드 클라우드 생성\n",
        "    for i, (type, text) in enumerate(grouped_data2.items()):\n",
        "\n",
        "        # 현재 전형이 들어갈 위치 계산\n",
        "        row_idx = i // MAX_COLS\n",
        "        col_idx = i % MAX_COLS\n",
        "\n",
        "        # 해당 위치에 중첩 GridSpec 생성\n",
        "        gs_nested = gs_main[row_idx, col_idx].subgridspec(10, 1, hspace=0.1)\n",
        "\n",
        "        # 서브 영역 할당\n",
        "        ax_wc = fig.add_subplot(gs_nested[0:8, 0]) # 워드 클라우드 영역\n",
        "        ax_text = fig.add_subplot(gs_nested[8:10, 0]) # 텍스트 영역\n",
        "\n",
        "        # 워드 클라우드 및 데이터 처리\n",
        "        result = keyword_counts(type, text)\n",
        "        keywords_list = result['keywords']\n",
        "\n",
        "        wc_type = WordCloud(\n",
        "            font_path=FONT_PATH,\n",
        "            width=800,\n",
        "            height=800,\n",
        "            background_color='white',\n",
        "            max_words=50\n",
        "        )\n",
        "        wordcloud_type = wc_type.generate(text)\n",
        "\n",
        "        # 워드 클라우드 시각화\n",
        "        ax_wc.imshow(wordcloud_type, interpolation='bilinear')\n",
        "        ax_wc.axis('off')\n",
        "        ax_wc.set_title(f\"전형: {type}\", fontproperties=title_font_prop)\n",
        "\n",
        "        # 주요 키워드 개수 출력\n",
        "        plot_keywords_on_axis(keywords_list, ax_text, title_font_prop, font_size=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"\\n'전형'별 그룹화할 데이터가 충분하지 않습니다.\")"
      ],
      "metadata": {
        "id": "_iXmpHMwK0mg"
      },
      "id": "_iXmpHMwK0mg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. 키워드 유사성 분포 분석(PCA)**   \n",
        "*   유사한 키워드들이 이루는 군집을 분석함\n",
        "*   TF-IDF를 이용해 키워드 중요도를 계산하고, 이를 이용하여 유사성을 판단함\n",
        "*   그래프에서 두 점이 가까울수록 그 학생들은 키워드 유사성이 높다고 해석할 수 있음\n"
      ],
      "metadata": {
        "id": "WgXCSZU81vbx"
      },
      "id": "WgXCSZU81vbx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. 키워드 중요도 계산 및 PCA 수행"
      ],
      "metadata": {
        "id": "LXCqDCcbI3QW"
      },
      "id": "LXCqDCcbI3QW"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "\n",
        "INPUT_CSV_FILE = 'keyword_processed_data.csv'\n",
        "FONT_PATH = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "\n",
        "\n",
        "# 한글 깨짐 방지 폰트 설정\n",
        "font_name = fm.FontProperties(fname=FONT_PATH).get_name()\n",
        "plt.rc('font', family=font_name)\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "title_font_prop = fm.FontProperties(fname=FONT_PATH, size=16)\n",
        "\n",
        "# 전처리 완료된 CSV 파일 로드\n",
        "try:\n",
        "    analysis_df = pd.read_csv(INPUT_CSV_FILE, encoding='utf-8-sig')\n",
        "    analysis_df['명사 리스트'] = analysis_df['명사 리스트'].fillna('')\n",
        "    analysis_df = analysis_df[analysis_df['명사 리스트'].str.strip().str.len() > 0].copy()\n",
        "    N = len(analysis_df)\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: '{INPUT_CSV_FILE}' 파일을 찾을 수 없습니다.\")\n",
        "    exit()\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=300, token_pattern=r'\\b\\w+\\b')\n",
        "documents = analysis_df['명사 리스트'].str.replace(', ', ' ').tolist()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# PCA를 위해 희소 행렬을 밀집 행렬로 변환\n",
        "tfidf_array = tfidf_matrix.toarray()\n",
        "print(f\"✅ TF-IDF 벡터 차원: {tfidf_array.shape}\")\n",
        "\n",
        "# PCA 수행\n",
        "# 주성분 2개로 차원 축소\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# PCA 모델 학습 및 데이터 변환\n",
        "pca_results = pca.fit_transform(tfidf_array)\n",
        "\n",
        "# PCA 결과를 DataFrame으로 정리\n",
        "pca_df = pd.DataFrame(data=pca_results, columns=['Principal Component 1', 'Principal Component 2'])\n",
        "# 학과 및 전형 정보 병합 (시각화 색상 구분 위해)\n",
        "pca_df = pd.concat([pca_df, analysis_df[['학과', '전형']].reset_index(drop=True)], axis=1)\n",
        "\n",
        "print(f\"✅ PCA 완료. 총 분산 설명률: {pca.explained_variance_ratio_.sum()*100:.2f}%\")"
      ],
      "metadata": {
        "id": "LE3g27GvDa06"
      },
      "id": "LE3g27GvDa06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. PCA 시각화"
      ],
      "metadata": {
        "id": "I3DI27fnPvB-"
      },
      "id": "I3DI27fnPvB-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1. 학과별 키워드 유사성 분포"
      ],
      "metadata": {
        "id": "35mWrHujP7O6"
      },
      "id": "35mWrHujP7O6"
    },
    {
      "cell_type": "code",
      "source": [
        "# 컴퓨터과학과와 그 외 학과를 구분함\n",
        "pca_df['학과 구분'] = pca_df['학과'].apply(lambda x: '컴퓨터과학과' if x == '컴퓨터과학과' else '그 외 학과')\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# '학과 구분'을 기준으로 산점도 생성\n",
        "sns.scatterplot(\n",
        "    x='Principal Component 1',\n",
        "    y='Principal Component 2',\n",
        "    hue='학과 구분',\n",
        "    data=pca_df,\n",
        "    s=150,\n",
        "    alpha=0.8\n",
        ")\n",
        "\n",
        "plt.title('키워드 유사성에 따른 학생 분포 (학과)', fontproperties=title_font_prop)\n",
        "plt.xlabel(f'주성분 1 ({pca.explained_variance_ratio_[0]*100:.2f}%)', fontproperties=title_font_prop)\n",
        "plt.ylabel(f'주성분 2 ({pca.explained_variance_ratio_[1]*100:.2f}%)', fontproperties=title_font_prop)\n",
        "\n",
        "# 범례\n",
        "legend = plt.legend(title='학과 구분', loc='best')\n",
        "plt.setp(legend.get_title(), fontproperties=title_font_prop)\n",
        "for text in legend.get_texts():\n",
        "    text.set_font_properties(fm.FontProperties(fname=FONT_PATH, size=12))\n",
        "\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4LIG5GkHKT8"
      },
      "id": "R4LIG5GkHKT8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2. 전형별 키워드 유사성 분포"
      ],
      "metadata": {
        "id": "NMqJoiAUQ4Pa"
      },
      "id": "NMqJoiAUQ4Pa"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# '전형'을 기준으로 산점도 생성\n",
        "sns.scatterplot(\n",
        "    x='Principal Component 1',\n",
        "    y='Principal Component 2',\n",
        "    hue='전형',\n",
        "    data=pca_df,\n",
        "    s=150,\n",
        "    alpha=0.8\n",
        ")\n",
        "\n",
        "plt.title('키워드 유사성에 따른 학생 분포 (전형)', fontproperties=title_font_prop)\n",
        "plt.xlabel(f'주성분 1 ({pca.explained_variance_ratio_[0]*100:.2f}%)', fontproperties=title_font_prop)\n",
        "plt.ylabel(f'주성분 2 ({pca.explained_variance_ratio_[1]*100:.2f}%)', fontproperties=title_font_prop)\n",
        "\n",
        "# 범례\n",
        "legend = plt.legend(title='전형', loc='best')\n",
        "plt.setp(legend.get_title(), fontproperties=title_font_prop)\n",
        "for text in legend.get_texts():\n",
        "    text.set_font_properties(fm.FontProperties(fname=FONT_PATH, size=12))\n",
        "\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i1pnbOx8EXZm"
      },
      "id": "i1pnbOx8EXZm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3. 학과 및 전형별 키워드 유사성 분포"
      ],
      "metadata": {
        "id": "TGIITW-4SULF"
      },
      "id": "TGIITW-4SULF"
    },
    {
      "cell_type": "code",
      "source": [
        "# 전형과 학과 구분을 결합한 새로운 컬럼 생성\n",
        "pca_df['전형_학과'] = pca_df['전형'] + '_' + pca_df['학과 구분']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "# '전형_학과'를 기준으로 산점도 생성\n",
        "sns.scatterplot(\n",
        "    x='Principal Component 1',\n",
        "    y='Principal Component 2',\n",
        "    hue='전형_학과',\n",
        "    data=pca_df,\n",
        "    s=150,\n",
        "    alpha=0.8\n",
        ")\n",
        "\n",
        "plt.title('키워드 유사성에 따른 학생 분포 (학과+전형)', fontproperties=title_font_prop)\n",
        "plt.xlabel(f'주성분 1 ({pca.explained_variance_ratio_[0]*100:.2f}%)', fontproperties=title_font_prop)\n",
        "plt.ylabel(f'주성분 2 ({pca.explained_variance_ratio_[1]*100:.2f}%)', fontproperties=title_font_prop)\n",
        "\n",
        "# 범례\n",
        "legend = plt.legend(title='전형 및 학과', loc='best')\n",
        "plt.setp(legend.get_title(), fontproperties=title_font_prop)\n",
        "for text in legend.get_texts():\n",
        "    text.set_font_properties(fm.FontProperties(fname=FONT_PATH, size=12))\n",
        "\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oh-Cmf2dKRso"
      },
      "id": "oh-Cmf2dKRso",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}